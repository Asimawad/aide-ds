{
  "nomad2018-predict-transparent-conductors": {
    "gold_threshold": 0.05589,
    "silver_threshold": 0.06229,
    "bronze_threshold": 0.06582,
    "median_threshold": 0.06988,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for nomad2018-predict-transparent-conductors...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"test.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\n# Target columns are 'formation_energy_ev_natom' and 'bandgap_energy_ev'.\n# ID column is 'id'.\ntarget_columns = [\"formation_energy_ev_natom\", \"bandgap_energy_ev\"]\nid_column_name_test = \"id\"\n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train, X_test from loaded data.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate (metric is mean column-wise RMSLE).\n# Ensure a variable `model` (or models) and `validation_score` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.5f}\")\n\n# --- Prediction ---\n# LLM: Generate predictions for the test set for both target columns.\n# Store predictions, e.g., in `test_predictions_target1` and `test_predictions_target2`.\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and the two target columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# final_submission_df = pd.DataFrame({\n#     id_column_name_test: test_df[id_column_name_test],\n#     target_columns[0]: test_predictions_target1,\n#     target_columns[1]: test_predictions_target2\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        dummy_df[target_columns[0]] = 0.0\n        dummy_df[target_columns[1]] = 0.0\n        if id_column_name_test in test_df.columns and id_column_name_test in dummy_df.columns:\n            dummy_df[id_column_name_test] = test_df[id_column_name_test].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df[id_column_name_test].values\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    fallback_data = {id_column_name_test: test_df[id_column_name_test] if id_column_name_test in test_df.columns else pd.Series(dtype='object')}\n    fallback_data[target_columns[0]] = 0.0\n    fallback_data[target_columns[1]] = 0.0\n    pd.DataFrame(fallback_data).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "denoising-dirty-documents": {
    "gold_threshold": 0.01794,
    "silver_threshold": 0.02609,
    "bronze_threshold": 0.04517,
    "median_threshold": 0.07325,
    "template": "import os\nimport pandas as pd\nimport numpy as np\nimport cv2 \n# from skimage import img_as_float32 # Example shows its use\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for denoising-dirty-documents...\")\ntrain_noisy_dir = os.path.join(BASE_INPUT_DIR, \"train\")\ntrain_cleaned_dir = os.path.join(BASE_INPUT_DIR, \"train_cleaned\") \ntest_noisy_dir = os.path.join(BASE_INPUT_DIR, \"test\")\n\ntrain_noisy_files = sorted([f for f in os.listdir(train_noisy_dir) if f.endswith(\".png\")])\ntest_noisy_files = sorted([f for f in os.listdir(test_noisy_dir) if f.endswith(\".png\")])\nprint(f\"Found {len(train_noisy_files)} training noisy images and {len(test_noisy_files)} test noisy images.\")\n\n# --- Feature Engineering ---\n# LLM: Define how images are processed/transformed for the model.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model (e.g., NLM, U-Net), train, validate. Metric is RMSE.\n# Ensure `validation_score` is calculated.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.6f}\")\n\n# --- Prediction ---\n# LLM: Generate denoised predictions for the test set images.\n# `test_predictions_denoised` might be a list of 2D numpy arrays (denoised images).\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' ('imageName_row_col') and 'value' (pixel intensity).\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# submission_rows = []\n# for i, test_file_name in enumerate(test_noisy_files):\n#     image_id_base = os.path.splitext(test_file_name)[0]\n#     denoised_image = test_predictions_denoised[i] \n#     H, W = denoised_image.shape\n#     for r_idx in range(H):\n#         for c_idx in range(W):\n#             submission_rows.append({\n#                 'id': f\"{image_id_base}_{r_idx+1}_{c_idx+1}\",\n#                 'value': denoised_image[r_idx, c_idx]\n#             })\n# final_submission_df = pd.DataFrame(submission_rows)\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        sample_sub_path = os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\") \n        if os.path.exists(sample_sub_path):\n             dummy_df = pd.read_csv(sample_sub_path, nrows=1000) \n             if 'value' in dummy_df.columns: dummy_df['value'] = 0.0\n             dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        else:\n            pd.DataFrame({'id': [], 'value': []}).to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    pd.DataFrame({'id': [], 'value': []}).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "random-acts-of-pizza": {
    "gold_threshold": 0.97908,
    "silver_threshold": 0.76482,
    "bronze_threshold": 0.6921,
    "median_threshold": 0.5995950000000001,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for random-acts-of-pizza...\")\ntrain_df = pd.read_json(os.path.join(BASE_INPUT_DIR, \"train.json\"))\ntest_df = pd.read_json(os.path.join(BASE_INPUT_DIR, \"test.json\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\")) \nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"requester_received_pizza\"\nid_column_name_test = \"request_id\"\n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train, X_test.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is ROC AUC.\n# Ensure `model` and `validation_score` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.4f}\")\n\n# --- Prediction ---\n# LLM: Generate probability predictions for the test set.\n# Store in `test_predictions_proba` (probability of class 1).\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'request_id' and 'requester_received_pizza' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# final_submission_df = pd.DataFrame({\n#     id_column_name_test: test_df[id_column_name_test],\n#     target_column_name: test_predictions_proba\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        dummy_df[target_column_name] = 0.5 \n        if id_column_name_test in test_df.columns and id_column_name_test in dummy_df.columns:\n             dummy_df[id_column_name_test] = test_df[id_column_name_test].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df[id_column_name_test].values\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    fallback_data = {id_column_name_test: test_df[id_column_name_test] if id_column_name_test in test_df.columns else pd.Series(dtype='object')}\n    fallback_data[target_column_name] = 0.5\n    pd.DataFrame(fallback_data).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "aerial-cactus-identification": {
    "gold_threshold": 1.0,
    "silver_threshold": 1.0,
    "bronze_threshold": 1.0,
    "median_threshold": 0.9991,
    "template": "import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for aerial-cactus-identification...\")\ntrain_labels_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"train.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\ntrain_images_dir = os.path.join(BASE_INPUT_DIR, \"train\")\ntest_images_dir = os.path.join(BASE_INPUT_DIR, \"test\")\ntest_image_ids = sorted([f for f in os.listdir(test_images_dir) if f.endswith('.jpg')])\nprint(f\"Found {len(train_labels_df)} training samples and {len(test_image_ids)} test samples.\")\ntarget_column_name = \"has_cactus\"\nid_column_name_test = \"id\"\n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train, X_test.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is ROC AUC.\n# Ensure `model` and `validation_score` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.4f}\")\n\n# --- Prediction ---\n# LLM: Generate predictions for the test set.\n# Store raw predictions in `test_predictions_raw`.\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and 'has_cactus' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# final_submission_df = pd.DataFrame({\n#     id_column_name_test: test_image_ids,\n#     target_column_name: test_predictions_raw\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        if 'id' in dummy_df.columns and id_column_name_test in test_df.columns and len(test_image_ids) == len(dummy_df):\n             dummy_df[id_column_name_test] = test_image_ids\n        if target_column_name in dummy_df.columns: dummy_df[target_column_name] = 0.5\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    pd.DataFrame({id_column_name_test: test_image_ids, target_column_name: np.zeros(len(test_image_ids))}).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "tabular-playground-series-may-2022": {
    "gold_threshold": 0.99823,
    "silver_threshold": 0.99822,
    "bronze_threshold": 0.99818,
    "median_threshold": 0.972675,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for tabular-playground-series-may-2022...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"test.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"target\"\nid_column_name_test = \"id\"\n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train, X_test. Handle f_27 (text/categorical).\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is ROC AUC.\n# Ensure `model` and `validation_score` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.5f}\")\n\n# --- Prediction ---\n# LLM: Generate probability predictions for the test set.\n# Store in `test_predictions_proba`.\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and 'target' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# final_submission_df = pd.DataFrame({\n#     id_column_name_test: test_df[id_column_name_test],\n#     target_column_name: test_predictions_proba\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        dummy_df[target_column_name] = 0.5\n        if id_column_name_test in test_df.columns and id_column_name_test in dummy_df.columns:\n             dummy_df[id_column_name_test] = test_df[id_column_name_test].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df[id_column_name_test].values\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    fallback_data = {id_column_name_test: test_df[id_column_name_test] if id_column_name_test in test_df.columns else pd.Series(dtype='object')}\n    fallback_data[target_column_name] = 0.5\n    pd.DataFrame(fallback_data).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "text-normalization-challenge-english-language": {
    "gold_threshold": 0.99724,
    "silver_threshold": 0.99135,
    "bronze_threshold": 0.99038,
    "median_threshold": 0.99037,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for text-normalization-challenge-english-language...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"en_train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"en_test_2.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"en_sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"after\"\n# Submission ID is 'sentence_id' + '_' + 'token_id'.\n\n# --- Feature Engineering / Rule Definition / Model Prep ---\n# LLM: Define logic to transform 'before' to 'after'.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation (if applicable) ---\n# LLM: If model-based, train and validate. Metric is accuracy.\n# Ensure `validation_score` is calculated.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.4f}\")\n\n# --- Prediction ---\n# LLM: Generate 'after' predictions for each 'before' token in test_df.\n# Store in `test_predictions_after`.\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and 'after' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# test_submission_ids = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n# final_submission_df = pd.DataFrame({\n#     'id': test_submission_ids,\n#     target_column_name: test_predictions_after\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"en_sample_submission.csv\"))\n        test_submission_ids_fallback = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n        dummy_df['id'] = test_submission_ids_fallback.values[:len(dummy_df)] if len(dummy_df) <= len(test_submission_ids_fallback) else test_submission_ids_fallback.values\n        dummy_df[target_column_name] = test_df['before'].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df['before'].values \n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    test_ids_fallback = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n    pd.DataFrame({'id': test_ids_fallback, target_column_name: test_df['before']}).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "mlsp-2013-birds": {
    "gold_threshold": 0.93527,
    "silver_threshold": 0.90038,
    "bronze_threshold": 0.87372,
    "median_threshold": 0.86572,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for mlsp-2013-birds...\")\nhist_path = os.path.join(BASE_INPUT_DIR, \"supplemental_data\", \"histogram_of_segments.txt\")\nfolds_path = os.path.join(BASE_INPUT_DIR, \"essential_data\", \"CVfolds_2.txt\")\nlabels_path = os.path.join(BASE_INPUT_DIR, \"essential_data\", \"rec_labels_test_hidden.txt\") \nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sampleSubmission.csv\"))\n\nhist_df = pd.read_csv(hist_path, header=None)\nrec_ids_from_hist = hist_df.iloc[:, 0].astype(int).values\nX_all_features = hist_df.iloc[:, 1:].values\n\nfolds_df = pd.read_csv(folds_path, header=None, names=[\"rec_id\", \"fold\"])\nfolds_df[\"rec_id\"] = folds_df[\"rec_id\"].astype(int)\n\nlabels_dict = {}\nnum_species = 19\nwith open(labels_path) as f:\n    for line in f:\n        parts = line.strip().split(\",\")\n        rid = int(parts[0])\n        if parts[1] == \"?\":\n            labels_dict[rid] = np.zeros(num_species, dtype=int) \n        else:\n            lbls_present = list(map(int, parts[1:]))\n            arr = np.zeros(num_species, dtype=int)\n            if lbls_present: arr[lbls_present] = 1\n            labels_dict[rid] = arr\n\ndata_df = pd.DataFrame({\"rec_id\": rec_ids_from_hist})\ndata_df = data_df.merge(folds_df, on=\"rec_id\", how=\"left\")\ndata_df[\"labels_array\"] = data_df[\"rec_id\"].map(labels_dict)\n\ntrain_mask = (data_df[\"fold\"] == 0) & data_df[\"labels_array\"].notna()\ntrain_indices = data_df[train_mask].index\nX_train_full = X_all_features[train_indices]\ny_train_full = np.vstack(data_df.loc[train_indices, \"labels_array\"].values)\n\ntest_submission_mask = (data_df[\"fold\"] != 0)\nsubmission_test_indices = data_df[test_submission_mask].index\nX_submission_test = X_all_features[submission_test_indices]\nsubmission_test_rec_ids = data_df.loc[submission_test_indices, \"rec_id\"].values\n\nprint(f\"Full train shape: {X_train_full.shape}, Full train labels shape: {y_train_full.shape}\")\nprint(f\"Submission test shape: {X_submission_test.shape}, Num test rec_ids: {len(submission_test_rec_ids)}\")\n\n# --- Feature Engineering ---\n# LLM: X_train_full, y_train_full, X_submission_test are prepared.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is mean Per-Class ROC AUC.\n# Ensure `model` and `validation_score` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.4f}\")\n\n# --- Prediction ---\n# LLM: Generate probability predictions for X_submission_test.\n# `test_predictions_proba` should be shape (n_test_samples, 19_species).\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'rec_id', 'species', 'probability' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# submission_rows = []\n# for i, rec_id_val in enumerate(submission_test_rec_ids):\n#     for species_idx in range(num_species):\n#         submission_rows.append({\n#             'rec_id': rec_id_val,\n#             'species': species_idx,\n#             'probability': test_predictions_proba[i, species_idx]\n#         })\n# final_submission_df = pd.DataFrame(submission_rows)\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_data_list = []\n        for rec_id_val in submission_test_rec_ids:\n            for species_idx in range(num_species):\n                dummy_data_list.append({'rec_id': rec_id_val, 'species': species_idx, 'probability': 0.0})\n        pd.DataFrame(dummy_data_list).to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    pd.DataFrame({'rec_id': [], 'species': [], 'probability': []}).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "text-normalization-challenge-russian-language": {
    "gold_threshold": 0.99012,
    "silver_threshold": 0.98232,
    "bronze_threshold": 0.97592,
    "median_threshold": 0.97591,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for text-normalization-challenge-russian-language...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"ru_train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"ru_test_2.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"ru_sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"after\"\n# Submission ID is 'sentence_id' + '_' + 'token_id'.\n\n# --- Feature Engineering / Rule Definition / Model Prep ---\n# LLM: Define logic to transform 'before' to 'after'.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation (if applicable) ---\n# LLM: If model-based, train and validate. Metric is accuracy.\n# Ensure `validation_score` is calculated.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.4f}\")\n\n# --- Prediction ---\n# LLM: Generate 'after' predictions for each 'before' token in test_df.\n# Store in `test_predictions_after`.\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and 'after' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# test_submission_ids = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n# final_submission_df = pd.DataFrame({\n#     'id': test_submission_ids,\n#     target_column_name: test_predictions_after\n# })\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"ru_sample_submission.csv\"))\n        test_submission_ids_fallback = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n        dummy_df['id'] = test_submission_ids_fallback.values[:len(dummy_df)] if len(dummy_df) <= len(test_submission_ids_fallback) else test_submission_ids_fallback.values\n        dummy_df[target_column_name] = test_df['before'].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df['before'].values\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    test_ids_fallback = test_df['sentence_id'].astype(str) + '_' + test_df['token_id'].astype(str)\n    pd.DataFrame({'id': test_ids_fallback, target_column_name: test_df['before']}).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "spooky-author-identification": {
    "gold_threshold": 0.16506,
    "silver_threshold": 0.26996,
    "bronze_threshold": 0.29381,
    "median_threshold": 0.418785,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for spooky-author-identification...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"test.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"author\"\nid_column_name_test = \"id\"\nauthor_classes = ['EAP', 'HPL', 'MWS'] \n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train (LabelEncoded), X_test.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is multi-class log_loss.\n# Ensure `model`, `validation_score`, and `model_classes_ordered` (e.g., ['EAP', 'HPL', 'MWS']) are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.5f}\")\n\n# --- Prediction ---\n# LLM: Generate probability predictions for the test set for each author.\n# Store in `test_predictions_proba` (shape [n_samples, 3_classes]).\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id', 'EAP', 'HPL', 'MWS' columns.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# submission_data = {id_column_name_test: test_df[id_column_name_test]}\n# for i, class_name in enumerate(model_classes_ordered): \n#     submission_data[class_name] = test_predictions_proba[:, i]\n# final_submission_df = pd.DataFrame(submission_data)\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        for author in author_classes: dummy_df[author] = 1.0/len(author_classes)\n        if id_column_name_test in test_df.columns and id_column_name_test in dummy_df.columns:\n            dummy_df[id_column_name_test] = test_df[id_column_name_test].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df[id_column_name_test].values\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    fallback_data = {id_column_name_test: test_df[id_column_name_test] if id_column_name_test in test_df.columns else pd.Series(dtype='object')}\n    for author in author_classes: fallback_data[author] = 1.0/len(author_classes)\n    pd.DataFrame(fallback_data).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  },
  "leaf-classification": {
    "gold_threshold": 0.0,
    "silver_threshold": 0.00791,
    "bronze_threshold": 0.01526,
    "median_threshold": 0.108345,
    "template": "import os\nimport pandas as pd\nimport numpy as np\n# LLM may add other imports\n\n# --- Static Paths ---\nBASE_INPUT_DIR = \"./input\"\nSUBMISSION_DIR = \"./submission\"\nSUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"submission.csv\")\n\n# --- Data Loading ---\nprint(\"Loading data for leaf-classification...\")\ntrain_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"test.csv\"))\nsample_submission_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\ntarget_column_name = \"species\"\nid_column_name_test = \"id\"\n# Species classes need to be determined by LLM (e.g., from sample_submission_df.columns[1:] or model.classes_)\n\n# --- Feature Engineering ---\n# LLM: Define X_train, y_train (LabelEncoded), X_test.\n\n# {{FEATURE_ENGINEERING_CODE}}\n\n# --- Model Training & Validation ---\n# LLM: Define model, train, validate. Metric is log_loss.\n# Ensure `model`, `validation_score`, and `model_classes_ordered` are defined.\n\n# {{MODEL_TRAINING_VALIDATION_CODE}}\n# print(f\"Validation Metric: {validation_score:.5f}\")\n\n# --- Prediction ---\n# LLM: Generate probability predictions for the test set for each species.\n# Store in `test_predictions_proba` (shape [n_samples, n_species_classes]).\n\n# {{PREDICTION_CODE}}\n\n# --- Submission File Generation ---\nprint(\"Preparing submission file...\")\n# LLM: Create `final_submission_df` with 'id' and one column per species class.\n\n# {{CREATE_FINAL_SUBMISSION_DATAFRAME_CODE}}\n# Example:\n# model_classes_ordered = sample_submission_df.columns[1:].tolist() # Get from sample if not from model\n# submission_data = {id_column_name_test: test_df[id_column_name_test]}\n# for i, class_name in enumerate(model_classes_ordered):\n#     submission_data[class_name] = test_predictions_proba[:, i]\n# final_submission_df = pd.DataFrame(submission_data)\n\n# Standard saving logic\nos.makedirs(SUBMISSION_DIR, exist_ok=True)\ntry:\n    if 'final_submission_df' in locals() and isinstance(final_submission_df, pd.DataFrame):\n        final_submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n        print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")\n    else:\n        print(\"Error: final_submission_df was not created. Saving dummy submission.\")\n        dummy_df = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n        num_classes_dummy = len(dummy_df.columns) - 1\n        if id_column_name_test in test_df.columns and id_column_name_test in dummy_df.columns:\n            dummy_df[id_column_name_test] = test_df[id_column_name_test].values[:len(dummy_df)] if len(dummy_df) <= len(test_df) else test_df[id_column_name_test].values\n        for col in dummy_df.columns:\n            if col != id_column_name_test: dummy_df[col] = 1.0 / num_classes_dummy if num_classes_dummy > 0 else 0.0\n        dummy_df.to_csv(SUBMISSION_FILE_PATH, index=False)\nexcept Exception as e:\n    print(f\"Error saving submission file: {e}. Saving basic dummy.\")\n    dummy_sub_fallback = pd.read_csv(os.path.join(BASE_INPUT_DIR, \"sample_submission.csv\"))\n    num_classes_fallback_safe = len(dummy_sub_fallback.columns) -1 if len(dummy_sub_fallback.columns) > 1 else 1\n    default_prob_fallback = 1.0 / num_classes_fallback_safe\n    fallback_data = {id_column_name_test: test_df[id_column_name_test] if id_column_name_test in test_df.columns else pd.Series(dtype='object') }\n    for col_name in dummy_sub_fallback.columns[1:]: fallback_data[col_name] = default_prob_fallback\n    pd.DataFrame(fallback_data).to_csv(SUBMISSION_FILE_PATH, index=False)\n\nprint(\"Script finished.\")\n"
  }
}