###############################################################################
# aide_config.yaml — pre-filled with your current settings
###############################################################################

# ─── Core paths ──────────────────────────────────────────────────────────────
data_dir: null
desc_file: null
goal: null
eval: null

# ─── Workflow / bookkeeping ─────────────────────────────────────────────────
log_dir: logs
log_level: DEBUG
workspace_dir: workspaces
competition_name: "MLE_BENCH_AIDE"
preprocess_data: true
copy_data: true
use_template: false
exp_name: null            # autogenerated when null

# ─── Runtime / execution engine ─────────────────────────────────────────────
inference_engine: vllm

exec:
  timeout: 600
  agent_file_name: runfile.py
  format_tb_ipython: false

# ─── Agent global hyper-params ──────────────────────────────────────────────
agent:
  steps: 25
  time_limit: 7200
  k_fold_validation: 5
  expose_prediction: false
  data_preview: true
  convert_system_to_user: false
  obfuscate: false
  ITS_Strategy: "Baseline"  #planner

  # ── LLM settings for coding ───────────────────────────────────────────────
  code:
    model: "o3-mini"
    planner_model: "RedHatAI/DeepSeek-R1-Distill-Qwen-14B-FP8-dynamic"
    temp: 0.6
    max_new_tokens: 2048
    top_p: 0.9
    top_k: 50
    num_return_sequences: 1

  # ── LLM settings for traceback / feedback ────────────────────────────────
  feedback:
    model: o3-mini
    temp: 0.5

  # ── Tree-search / debugging heuristics ───────────────────────────────────
  search:
    max_debug_depth: 5
    debug_prob: 0.7
    num_drafts: 5

# ─── W&B experiment tracking ────────────────────────────────────────────────
wandb:
  enabled: true
  project: "MLE_BENCH_AIDE"
  entity: null
  run_name: null
  log_code: true
  log_artifacts: true
