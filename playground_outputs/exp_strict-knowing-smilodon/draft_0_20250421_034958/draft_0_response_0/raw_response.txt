Okay, so I need to solve this Kaggle competition problem where I have to predict the author of a sentence as one of three: Poe, Lovecraft, or Shelley. The task is to build a machine learning model that can accurately classify the author of a given text. 

First, I should understand the problem thoroughly. The goal is to predict the author based on the text content. The data provided includes three columns: EAP, HPL, and MWS, which are float values representing different metrics. These metrics likely correspond to the author's style or characteristics. The task is to use this data to predict the author.

I need to plan the approach. Since the task is classification with three possible outcomes, I can use a classification model. The evaluation metric should be multi-class logarithmic loss, which is suitable for this scenario. 

For the model, I can use a Random Forest classifier because it's robust and can handle various types of data well. It's also easy to interpret, which is good for understanding the model's predictions.

Now, for the data, I have three datasets: train, test, and sample_submission. I'll need to load all of them. The data is already prepared, so I don't need to preprocess it further. I'll use pandas to read the CSV files.

The plan is to load the data, extract the EAP, HPL, MWS features, and then use them as features to train the model. The target variable is the author, which has three categories. I'll split the data into training and validation sets to evaluate the model's performance.

I'll implement a Random Forest classifier with these features. After training, I'll evaluate it using the validation set and print the multi-class logarithmic loss. Finally, I'll generate predictions for the test set and save them to the specified path.

I need to ensure that the code is clean and well-structured. I'll write the code in a single Python file, using pandas for data loading and manipulation, and scikit-learn for the Random Forest classifier. I'll also make sure to print the evaluation metric clearly.

I should also consider any potential issues, like overfitting, but since the model is a Random Forest, it's less prone to overfitting compared to other models. I'll also make sure to handle the data correctly, ensuring that the text data is properly processed and that the features are correctly extracted.

In summary, the plan is to use a Random Forest classifier with the given features to predict the author of a sentence, evaluate it using multi-class logarithmic loss, and generate predictions for the test set.
</think>

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, log_loss
from sklearn.model_selection import train_test_split

# Load data
train = pd.read_csv('input/train.csv')
test = pd.read_csv('input/test.csv')
sample_submission = pd.read_csv('input/sample_submission.csv')

# Prepare data
X = train[['EAP', 'HPL', 'MWS']]
y = train['author']

# Split into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize model
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)

# Train model
rf.fit(X_train, y_train)

# Evaluate model
y_pred = rf.predict(X_val)
loss = log_loss(y_val, y_pred)
print(f'Validation Loss: {loss}')

# Generate predictions for test set
y_pred_test = rf.predict(X_test)
y_pred_test_proba = rf.predict_proba(X_test)

# Save predictions
submission_path = 'submission/submission.csv'
pd.DataFrame({'id': X_test['id'], 'author': y_pred_test}).to_csv(submission_path, index=False)
```