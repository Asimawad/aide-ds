Okay, so I need to solve this Kaggle competition problem where I have to predict the author of a sentence as one of three: Poe, Lovecraft, or Shelley. The task is to build a machine learning model that can accurately classify the author of a given text. 

First, I should understand the problem thoroughly. The goal is to predict the author based on the text content. The data provided includes three columns: EAP, HPL, and MWS, which are float values representing different metrics. These metrics likely correspond to the author's style or characteristics. The task is to use this data to predict the author.

I need to plan the approach. Since the task is classification with three possible outcomes, I can use a classification model. Multi-class classification is suitable here. I should consider using a decision tree, random forest, or a neural network. However, given the nature of the data, which seems to have float values, I might need to preprocess the data to extract features that can help in classification.

Looking at the data, the text is in the 'text' column, and the float values are in 'EAP', 'HPL', and 'MWS'. I think these float values could be features that represent some characteristics of the author. For example, EAP might be the percentage of sentences written by EAP, HPL by HPL, and MWS by Shelley. So, perhaps I can use these as features to train a model.

Next, I need to think about the evaluation metric. The problem mentions using multi-class logarithmic loss. So, I should choose a model that can handle multi-class classification and report this loss as the evaluation metric.

For the model, I can use a Random Forest classifier because it's robust and can handle various types of data well. It's also easy to interpret, which might be helpful for understanding the model's decisions.

Now, for the data preprocessing, I should consider normalizing the float values since they are continuous and might have different scales. Also, the text data needs to be processed to extract meaningful features. Maybe using TF-IDF or word embeddings could help. However, since the float values are already provided, perhaps they can be used as features directly.

I should also consider feature engineering, like extracting n-grams or other text features, but that might be overcomplicating. For now, using the float values as features might be sufficient.

In terms of data splitting, I'll need to split the dataset into training, validation, and test sets. The training set will be used to train the model, the validation set to tune hyperparameters, and the test set to evaluate the final model's performance.

I need to make sure that the data is properly preprocessed, handling any missing values or irrelevant features. Since the float values are the main features, I'll focus on those.

For the model, I'll use scikit-learn's Random Forest classifier. I can set it to multi-class and use logloss as the scoring metric.

In the code, I'll start by importing necessary libraries like pandas for data handling, numpy for numerical operations, and sklearn for the model and metrics. I'll load the data from the input directory. Then, I'll split the data into training and test sets. I'll use the float values as features and the author as the target variable.

I'll train the model, use cross-validation to avoid overfitting, and then evaluate it on the test set. Finally, I'll print the evaluation metric, which is the logloss.

I should also ensure that the code is well-structured and follows best practices, like using clear variable names and keeping the code readable.

Now, putting it all together, I'll outline the steps and write the code accordingly.
</think>

```python
# Plan
1. Understand the task: Predict the author of a sentence as one of three: Poe, Lovecraft, or Shelley.
2. Use multi-class classification model.
3. Use logloss as evaluation metric.
4. Preprocess data: Normalize float values, extract features from text.
5. Split data into training, validation, and test sets.
6. Implement Random Forest classifier for multi-class classification.
7. Use cross-validation for model evaluation.
8. Print logloss on test set.

# Code
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import log_loss
from sklearn.preprocessing import StandardScaler

# Load data
data = pd.read_csv('input/sample_submission.csv')

# Split data into features and target
X = data[['EAP', 'HPL', 'MWS']]
y = data['author']

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define Random Forest classifier
rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)

# Hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'max_features': ['auto', 'log2']
}

grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='log_loss')
grid_search.fit(X_train, y_train)

# Get best parameters
best_params = grid_search.best_params_
print(f"Best parameters: {best_params}")

# Train final model
rf_final = RandomForestClassifier(n_estimators=best_params['n_estimators'], 
                               max_depth=best_params['max_depth'], 
                               max_features=best_params['max_features'], 
                               random_state=42)
rf_final.fit(X_train, y_train)

# Make predictions
y_pred = rf_final.predict(X_test)

# Calculate logloss
logloss = log_loss(y_test, y_pred)
print(f"Logloss: {logloss:.3f}")
```